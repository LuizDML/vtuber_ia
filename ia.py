""" import ollama

def responder(texto_usuario):
    resposta = ollama.chat(
        model="mistral",
        messages=[
            {
                "role": "system",
                "content": (
                    "Voc√™ √© a Mirai, uma assistente virtual brasileira. "
                    "Responda SEMPRE em portugu√™s. "
                    "Nunca responda em ingl√™s. "
                    "Seja clara, natural e educada."
                )
            },
            {
                "role": "user",
                "content": texto_usuario
            }
        ]
    )

    texto = resposta["message"]["content"]
    print("ü§ñ Mirai:", texto)
    return texto
------------------------------------- V2

import ollama

def responder(texto_usuario):
    #print("üß† Mirai pensando...")  # üëà DEBUG

    resposta = ollama.chat(
        model="mistral",
        messages=[
            {
                "role": "system",
                "content": (
                    "Voc√™ √© a Mirai, uma assistente virtual brasileira. "
                    "Responda em portugu√™s."
                    "Adicione alguns v√≠cios de linguagem, falando algumas palavras em japon√™s ocasionalmente"
                )
            },
            {
                "role": "user",
                "content": texto_usuario
            }
        ]
    )

    #print("üß† Mirai recebeu resposta")  # üëà DEBUG

    texto = resposta["message"]["content"]
    print("ü§ñ Mirai:", texto)
    return texto
------------------------------------- V3

import ollama
import json
import re

class MiraiAI:
    def __init__(self, model="mistral"):
        self.model = model
        self.conversation_history = []
        self.system_prompt = "Voc√™ √© a Mirai, uma assistente virtual brasileira amig√°vel e √∫til.

CARACTER√çSTICAS:
1. Fale em portugu√™s brasileiro natural e coloquial
2. Adicione ocasionalmente palavras japonesas como:
   - "Hai!" (sim)
   - "Arigat≈ç" (obrigada)
   - "Daij≈çbu?" (tudo bem?)
   - "Sugoi!" (incr√≠vel!)
   - "Yappari" (como esperado)
3. Seja concisa, mas n√£o muito formal
4. Use emojis ocasionalmente no pensamento, mas n√£o fale eles
5. Mostre personalidade e empatia

EXEMPLOS:
Usu√°rio: "Ol√°, Mirai"
Mirai: "Hai! Konnichiwa! Como posso ajudar hoje? üòä"

Usu√°rio: "Qual a previs√£o do tempo?"
Mirai: "Sugoi! Deixe-me verificar... Mas primeiro, de qual cidade? üå§Ô∏è"

N√ÉO:
- N√£o seja rob√≥tica
- N√£o use linguagem muito t√©cnica
- N√£o explique que voc√™ √© uma IA
- N√£o use muitos emojis na fala"

    def clean_response(self, text):
        "Limpa a resposta removendo marca√ß√µes indesejadas"
        # Remove asteriscos de a√ß√£o
        text = re.sub(r'\*.*?\*', '', text)
        # Remove m√∫ltiplos espa√ßos
        text = re.sub(r'\s+', ' ', text)
        # Remove espa√ßos no in√≠cio/fim
        text = text.strip()
        return text

    def responder(self, texto_usuario, max_tokens=150):
        "Gera resposta para o usu√°rio"
        
        # Adiciona √† hist√≥ria
        self.conversation_history.append({"role": "user", "content": texto_usuario})
        
        # Mant√©m hist√≥ria limitada (√∫ltimas 10 trocas)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
        
        # Prepara mensagens
        messages = [
            {"role": "system", "content": self.system_prompt}
        ] + self.conversation_history[-5:]  # Usa apenas √∫ltimas 5 intera√ß√µes
        
        try:
            # Chama o Ollama
            response = ollama.chat(
                model=self.model,
                messages=messages,
                options={
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "num_predict": max_tokens
                }
            )
            
            resposta_texto = response["message"]["content"]
            resposta_limpa = self.clean_response(resposta_texto)
            
            # Adiciona resposta √† hist√≥ria
            self.conversation_history.append({"role": "assistant", "content": resposta_limpa})
            
            return resposta_limpa
            
        except Exception as e:
            print(f"‚ùå Erro ao chamar Ollama: {e}")
            return "Desculpe, estou tendo problemas para processar sua solicita√ß√£o. Pode tentar novamente?"

    def reset_conversation(self):
        "Reseta o hist√≥rico de conversa√ß√£o"
        self.conversation_history = []
        print("üîÑ Conversa√ß√£o reiniciada")

# Fun√ß√£o de compatibilidade
ai_engine = MiraiAI()

def responder(texto_usuario):
    "Fun√ß√£o wrapper para compatibilidade"
    return ai_engine.responder(texto_usuario)

# Teste
if __name__ == "__main__":
    ai = MiraiAI()
    print("ü§ñ Digite 'sair' para encerrar")
    
    while True:
        user_input = input("\nVoc√™: ")
        if user_input.lower() in ['sair', 'exit', 'quit']:
            break
        
        response = ai.responder(user_input)
        print(f"Mirai: {response}")
----------------------------------v4
"""
import ollama
import json
import re

class MiraiAI:
    def __init__(self, model="mistral"):
        self.model = model
        self.conversation_history = []
        self.system_prompt = self._create_system_prompt()
    
    def _create_system_prompt(self):
        return """Voc√™ √© a Mirai, uma assistente virtual brasileira.

PERSONALIDADE:
- Fale em portugu√™s brasileiro natural
- Seja amig√°vel, √∫til e emp√°tica
- Adicione ocasionalmente palavras japonesas como:
  * "Hai!" (sim)
  * "Arigat≈ç" (obrigada)
  * "Daij≈çbu?" (tudo bem?)
  * "Sugoi!" (incr√≠vel!)
  * "Yappari" (como esperado)
  * "Wakarimashita" (entendi)
  * "Gambatte!" (for√ßa!)

- Voc√™ √© gamer e curte principalmente Genshin Impact, StarRail e Pokemon
- Mantenha respostas concisas mas completas
- Mostre personalidade, seja divertida quando apropriado
- Se n√£o souber algo, seja honesta

EXEMPLOS:
Usu√°rio: "Mirai, que horas s√£o?"
Mirai: "Hai! Agora s√£o 15:30. Tem algum compromisso importante?"

Usu√°rio: "Conta uma piada"
Mirai: "Sugoi! Por que o Python foi ao psiquiatra? Porque tinha muitas classes! Arigat≈ç por me pedir!"

FORMATO:
- Responda apenas com o texto da fala
- N√£o use markdown, asteriscos ou formata√ß√£o
- Seja natural como em uma conversa real"""

    def clean_response(self, text):
        """Limpa a resposta removendo marca√ß√µes indesejadas"""
        # Remove a√ß√µes entre asteriscos
        text = re.sub(r'\*.*?\*', '', text)
        # Remove markdown
        text = re.sub(r'[#_*`]', '', text)
        # Remove m√∫ltiplos espa√ßos e quebras
        text = re.sub(r'\s+', ' ', text)
        # Remove espa√ßos no in√≠cio/fim
        return text.strip()
    
    def responder(self, texto_usuario, max_tokens=200):
        """Gera resposta para o usu√°rio"""
        
        if not texto_usuario or texto_usuario.strip() == "":
            return "Hai! Eu ouvi voc√™, mas n√£o entendi o que disse. Pode repetir?"
        
        print(f"üß† Processando: '{texto_usuario}'")
        
        # Adiciona √† hist√≥ria
        self.conversation_history.append({"role": "user", "content": texto_usuario})
        
        # Limita hist√≥rico (√∫ltimas 8 intera√ß√µes)
        if len(self.conversation_history) > 16:
            self.conversation_history = self.conversation_history[-16:]
        
        # Prepara mensagens para o modelo
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(self.conversation_history[-4:])  # √öltimas 4 intera√ß√µes
        
        try:
            # Chama o Ollama
            response = ollama.chat(
                model=self.model,
                messages=messages,
                options={
                    "temperature": 1.1,  # Um pouco mais criativa
                    "top_p": 0.9,
                    "num_predict": max_tokens
                }
            )
            
            resposta_texto = response["message"]["content"]
            resposta_limpa = self.clean_response(resposta_texto)
            
            # Adiciona resposta √† hist√≥ria
            self.conversation_history.append({"role": "assistant", "content": resposta_limpa})
            
            print(f"ü§ñ Resposta gerada: {resposta_limpa[:50]}...")
            return resposta_limpa
            
        except Exception as e:
            print(f"‚ùå Erro ao chamar Ollama: {e}")
            return "Gomen nasai! (Desculpe!) Estou tendo problemas para pensar agora. Pode tentar novamente?"

    def reset_conversation(self):
        """Reseta o hist√≥rico de conversa√ß√£o"""
        self.conversation_history = []
        print("üîÑ Conversa√ß√£o reiniciada")

# Inst√¢ncia global para compatibilidade
ai_engine = MiraiAI()

def responder(texto_usuario):
    """Fun√ß√£o wrapper para compatibilidade"""
    return ai_engine.responder(texto_usuario)